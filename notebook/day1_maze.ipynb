{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pythonで学ぶ強化学習　ハンズオン"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day1 （強化学習の位置付けを知る）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 強化学習は学習方法の一種（抜粋）\n",
    "- 教師有り学習\n",
    "    - データと正解ラベルをセットで与える。　データが与えられたらラベルが出力されるようパラメータを調整。\n",
    "- 教師なし学習\n",
    "    - データのみを与えてデータの特徴（構造や表現）を抽出できるようパラメータを調整。\n",
    "- 強化学種\n",
    "    - 行動により報酬が得られる環境（タスク）を与えて、各状態で報酬に繋がる行動が出力される行動が出力されるようモデルのパラメータを調整。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 強化学習における問題設定: Markov Desiosion Process\n",
    "\n",
    "- 強化学習における「環境」は以下の要素からなる**マルコフ決定過程（Markov Desiosion Process）**からなる。\n",
    "    - $s$ : **状態 （state）**\n",
    "    - $a$ : **行動 （action）**\n",
    "    - $T$ : 状態遷移の確率（**遷移関数 / Transition function**）。状態$s$と行動$a$を引数に、遷移先$s^{\\prime}$（次の状態）と遷移確率を出力する関数。\n",
    "    - $R$ : **報酬関数 （Reward function）**。状態$s$と遷移先$s^{\\prime}$を引数に、報酬を出力する関数（行動$a$を引数に取ることもある）。\n",
    "    \n",
    "\n",
    "- **エピソード （Episode）**: 環境の開始から終了までの期間。\n",
    "\n",
    "- **戦略** $\\pi$: 状態$s$を受け取り、行動$a$を決める関数。\n",
    "\n",
    "- **エージェント**: 戦略$\\pi$に従って行動する主体。（強化学習では戦略がモデルとなり、パラメーターを調節して適切な行動を出力する）\n",
    "\n",
    "- **即時報酬 （Immediate reward）**: MDPにおける報酬 $r$（$:= R(s, s^{\\prime})$）。\n",
    "\n",
    "- **期待報酬（Expected reward）** / **価値（Value）**: 報酬の総和\n",
    "\n",
    "- **価値評価（Value apploximation）**: 価値を算出すること。\n",
    "\n",
    "MDPにおける時刻$t$ から時刻$T$ までの「報酬の総和」は**割引率（Discount factor）** $\\gamma$を用いて以下のように書ける。\n",
    "\n",
    "$$G_{t} := r_{t+1} + \\gamma r_{t+2} + \\gamma^{2}r_{t+2} + \\cdots + \\gamma^{T-t-1}r_{tT} = \\sum_{k=0}^{T-t+1}\\gamma^{k}r_{t+k+1}$$\n",
    "\n",
    "\n",
    "価値$G_{t}$は時刻$t+1$での価値を用いて、再帰的に以下のように書ける。\n",
    "\n",
    "$$G_{t} = r_{t+1} + \\gamma G_{t+1}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Example(迷路)\n",
    "\n",
    "簡単な迷路における、MDPの構成要素は以下である。\n",
    "\n",
    "- $s$ 状態 : セルの位置（行/列）\n",
    "- $a$ 行動 : 上下左右への移動\n",
    "- $T$ 遷移関数: 状態と行動を受け取り、移動可能なセルとそこへの遷移確率を返す関数\n",
    "- $R$ 報酬関数: 状態を受け取り、緑(ゴール)のセルなら1、赤(ペナルティ)のセルなら-1を返す関数\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 位置クラス(状態$s$)、上下移動クラス（行動$a$）の実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "# セル位置表現クラス\n",
    "class State:\n",
    "    def __init__(self, row: int=-1, column: int=-1):\n",
    "        self.row = row\n",
    "        self.column = column\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"State: [{self.row}, {self.column}]\"\n",
    "    \n",
    "    def clone(self):\n",
    "        return State(self.row, self.column)\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash((self.row, self.column))\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return self.row == other.row and self.column == other.column\n",
    "    \n",
    "# アクション定義クラス\n",
    "class Action(Enum):\n",
    "    UP = 1\n",
    "    DOWN = -1\n",
    "    LEFT = 2\n",
    "    RIGHT = -2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State: [3, 5]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "State(3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Action.UP: 1>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Action.UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Action.UP: 1>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Action(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 環境実態クラス(雛形)を実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "\n",
    "# 迷路環境実態クラス\n",
    "class Environment:\n",
    "    def __init__(self, grid: List[List[int]], move_prob: float=0):\n",
    "        \"\"\"\n",
    "        エージェントがゴールを早く目指すように、デフォルトの報酬を負値に定義。\n",
    "        エージェントは選択した向きにmove_probの確率で移動し、(1 - move_prob)の確率で他の方向に進む。\n",
    "        \"\"\"\n",
    "        # grid is 2d-Array. Its values are treated as an attribute.\n",
    "        # kinds of attributes is following\n",
    "        # 0: ordinary cell\n",
    "        # -1: damage cell (game end)\n",
    "        # 1: reward cepp (game end)\n",
    "        # 9: block cell (can't locate agent)\n",
    "        self.grid = grid\n",
    "        self.agent_state = State()\n",
    "        self.default_reward = -0.04\n",
    "        self.move_prob = move_prob\n",
    "        self.reset()\n",
    "        \n",
    "    @property\n",
    "    def row_length(self) -> int:\n",
    "        return len(self.grid)\n",
    "    \n",
    "    @property\n",
    "    def column_length(self) -> int:\n",
    "        return len(self.grid[0])\n",
    "    \n",
    "    @property\n",
    "    def actions(self) -> List[Action]:\n",
    "        return [Action.UP, Action.DOWN, Action.LEFT, Action.RIGHT]\n",
    "    \n",
    "    @property\n",
    "    def states(self) -> List[State]:\n",
    "        \"\"\"\n",
    "        迷路内の移動可能なセルを返す。(ブロックセルを除外)\n",
    "        \"\"\"\n",
    "        states = []\n",
    "        for row in range(self.row_length):\n",
    "            for col in range(self.column_lengthh):\n",
    "                if self.grid[row][col] != 9:\n",
    "                    states.append(State(row, col))\n",
    "        return states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 遷移関数$T$と報酬関数$R$の実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment(Environment):\n",
    "    def transition_func(self, state: State, action: Action) -> Dict[State, float]:\n",
    "        \"\"\"\n",
    "        状態とアクションを受けとり、次の状態への遷移確率を返す。\n",
    "        今回の迷路では、move_probの確率で選択した方向に、(1-move_prob)の確率で、選択した方向との反対以外の方向に等確率で遷移する。\n",
    "        \"\"\"\n",
    "        transition_probs = {}\n",
    "        for suggest_action in self.actions:\n",
    "            next_state = self._move(state, suggest_action)\n",
    "            \n",
    "            if suggest_action == action:\n",
    "                prob = move_prob\n",
    "            elif suggest_action.value + action.value != 0:\n",
    "                prob = (1 - move_prob) / 2\n",
    "            else:\n",
    "                prob = 0\n",
    "                \n",
    "            transition_probs[next_state] = prob\n",
    "        \n",
    "        return transition_probs\n",
    "    \n",
    "    def can_action_at(self, state: State) -> bool:\n",
    "        \"\"\"\n",
    "        stateがアクション可能なセルかどうか判定\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if self.grid[state.row][state.column] == 0:\n",
    "                True\n",
    "            else:\n",
    "                False\n",
    "        except IndexError as e:\n",
    "            raise ValueError(f\"This state is out of mase! {state}\")\n",
    "    \n",
    "    def _move(self, state: State, aciton) -> State:\n",
    "        \"\"\"\n",
    "        位置とアクションを受け取り、アクション可能な位置であれば受け取ったアクション方向に移動した位置に移動する。\n",
    "        移動先位置が迷路の外であれば、そのままの位置を返す。\n",
    "        \"\"\"\n",
    "        if not self.can_action_at:\n",
    "            raise ValueError(\"Can't move from here!\")\n",
    "        \n",
    "        next_state = state.clone()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
